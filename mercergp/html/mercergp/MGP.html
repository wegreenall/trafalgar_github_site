<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>mercergp.MGP API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>mercergp.MGP</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import torch

from ortho.basis_functions import (
    smooth_exponential_basis,
    smooth_exponential_eigenvalues,
    Basis,
)
from mercergp.kernels import MercerKernel
import matplotlib.pyplot as plt


class HilbertSpaceElement:
    &#34;&#34;&#34;
    A class representing an element of  Hilbert space.
    That is, for a given basis and set of coefficients, instances of this class
    represent functions that belong to the corresponding Hilbert space.

    This is useful when producing Mercer Gaussian Processes.
    &#34;&#34;&#34;

    def __init__(self, basis, coefficients):
        self.basis = basis
        self.coefficients = coefficients
        self.order = len(coefficients)
        return

    def __call__(self, x):
        &#34;&#34;&#34;
        Evaluates the Hilbert Space element at the given inputs x.
        &#34;&#34;&#34;
        return torch.inner(self.coefficients, self.basis(x)).squeeze()

    def get_order(self):
        &#34;&#34;&#34;
        Getter method for recalling the order of the model; i.e. the bandwidth
        of the kernel whose reproducing space this is an element of.
        &#34;&#34;&#34;
        return self.order

    def get_coefficients(self):
        &#34;&#34;&#34;
        Getter method for recalling the coefficients that this Hilbert Space
        element this is comprised of.
        &#34;&#34;&#34;
        return self.coefficients


class MercerGP:
    &#34;&#34;&#34;
    A class representing a Mercer Gaussian Process.
    &#34;&#34;&#34;

    def __init__(
        self,
        basis: Basis,
        order: int,
        dim: int,
        kernel: MercerKernel,
        mean_function=lambda x: torch.zeros(x.shape),
    ):
        &#34;&#34;&#34;
        : param basis: a Basis class instance
        : param order:  integer describing the maximum order of the kernel
                        truncation
        :param dim: an integer describing the dimension of the model
        : param kernel: a MercerKernel instance
        : param mean_function: a callable representing the
                            prior mean function for the GP.

        Note on the mean_function callable:
        Because it is feasible that the mean function might not be expressed
        as an element of the Hilbert space, we treat it as a direct callable
        function rather than a set of coefficients for the functions in the
        same space.
        &#34;&#34;&#34;
        self.basis = basis
        self.order = order
        self.kernel = kernel
        self.dim = dim

        # data placeholders
        self.x = torch.Tensor([])
        self.y = torch.Tensor([])

        # stored as a closure - see dosctring
        self.mean_function = mean_function
        # self.posterior_coefficients = torch.zeros([self.order])
        return

    def add_data(self, x, y):
        &#34;&#34;&#34;
        Adds observation data for the given MercerGP.

        :param x: the inputs
        :param y: the outputs
        &#34;&#34;&#34;
        # add the inputs and alter the coefficients
        self.x = torch.cat([self.x, x])
        self.y = torch.cat([self.y, y])

        self.posterior_coefficients = self._calculate_posterior_coefficients()
        return

    def get_inputs(self):
        &#34;&#34;&#34;
        Getter method for recalling the inputs that have been passed to the
        MercerGP.
        &#34;&#34;&#34;
        return self.x

    def get_targets(self):
        &#34;&#34;&#34;
        Getter method for recalling the outputs that have been passed to the
        MercerGP.

        Note that this returns the raw targets, rather than processed outputs
        including the mean function m(x).
        For that, MercerGP.get_posterior_mean(x) may be more relevant.
        &#34;&#34;&#34;
        return self.y

    def get_outputs(self):
        &#34;&#34;&#34;
        outputs the data added to the MercerGP minus the mean function
        at the inputs, for correct construction of the coefficients.
        &#34;&#34;&#34;
        return self.y - self.mean_function(self.get_inputs())

    def get_posterior_mean(self):
        &#34;&#34;&#34;
        Returns the posterior mean function.&#34;&#34;&#34;
        return MercerGPSample(
            self.basis, self.posterior_coefficients, self.mean_function
        )

    def gen_gp(self):
        &#34;&#34;&#34;
        Returns a MercerGPSample object representing the sampled Gaussian
        process. It does this by having on it the basis functions and the set
        coefficients.
        &#34;&#34;&#34;
        # return a MercerGPSample
        return MercerGPSample(
            self.basis,
            self._get_sample_coefficients() + self.posterior_coefficients,
            self.mean_function,
        )

    def _calculate_posterior_coefficients(self):
        &#34;&#34;&#34;
        Returns the non-random coefficients for the posterior mean according
        to the kernel as added to the Gaussian process, and under the data
        passed to the Mercer Gaussian process. This will be zeroes for no
        targets

        That is, these are the poeterior mean coefficients related to
        (y-m)&#39;(K(x, x) + σ^2I)^{-1}
        &#34;&#34;&#34;
        interim_matrix = self.kernel.get_interim_matrix_inverse(self.x)
        ksi = self.kernel.get_ksi(self.x)

        posterior_coefficients = torch.einsum(
            &#34;jm, mn -&gt; jn&#34;, interim_matrix, ksi.t()
        )
        these_outputs = self.get_outputs()
        result = torch.einsum(
            &#34;i..., ji -&gt; j&#34;, these_outputs, posterior_coefficients
        )
        return result

    def _get_sample_coefficients(self):
        &#34;&#34;&#34;
        Returns random coefficients for a sample according to the kernel.

        Combined with posterior coefficients, these are used to produce a GP
        sample.
        &#34;&#34;&#34;
        mean = torch.zeros([self.order])
        variance = self.kernel.get_interim_matrix_inverse(self.x)
        # variance *= 100
        if (variance != torch.abs(variance)).all():
            breakpoint()
        # variance += 0.001 * torch.eye(variance.shape[0])
        normal_rv = (
            torch.distributions.MultivariateNormal(
                loc=mean, covariance_matrix=variance
            )
            .sample([1])
            .squeeze()
        )
        return normal_rv

    def set_posterior_coefficients(self, coefficients):
        self.posterior_coefficients = coefficients


class MercerGPSample(HilbertSpaceElement):
    &#34;&#34;&#34;
    Subclassing the HilbertSpaceElement,
    this adds a passed mean function so as to represent a GP sample function.
    &#34;&#34;&#34;

    def __init__(self, basis, coefficients, mean_function):
        &#34;&#34;&#34;
        Modifies the super init to store the mean function callable
        &#34;&#34;&#34;
        super().__init__(basis, coefficients)
        self.mean_function = mean_function
        return

    def __call__(self, x):
        &#34;&#34;&#34;
        Adds the mean function evaluation to the MercerGPSample
        &#34;&#34;&#34;
        return super().__call__(x) + self.mean_function(x)


class HermiteMercerGPSample(MercerGPSample):
    &#34;&#34;&#34;
    Subclassing the MercerGPSample,
    this represents specifically a sample from a MercerGP with a truncated
    smooth exponential kernel via the use of the Mercer kernel representation.


    &#34;&#34;&#34;

    def __init__(
        self,
        coefficients,
        dim,
        params,
        mean_function,
        mean_function_derivative,
    ):
        se_basis = Basis(
            smooth_exponential_basis, dim, len(coefficients), params
        )

        derivative_se_basis = Basis(
            smooth_exponential_basis, dim, len(coefficients) + 1, params
        )

        super().__init__(se_basis, coefficients, mean_function)

        # prepare the derivative function for when necessary
        dfc_1 = torch.Tensor(
            [
                torch.sqrt(torch.tensor(2 * (i - 1 + 1)))
                for i in range(self.order + 1)
            ]
        )
        dfc_2 = torch.cat((torch.Tensor([0]), self.coefficients))
        self.df_second_gp = HilbertSpaceElement(
            derivative_se_basis, dfc_1 * dfc_2
        )

        self.mean_function_derivative = mean_function_derivative
        return

    def derivative(self, x):
        &#34;&#34;&#34;
        Returns the derivative of this sample, evaluated at x.

        The MercerGPSample, if using the smooth exponential basis,
        is able to produce its own derivative. This may also be true for
        the Chebyshev ones as well.

        The sample derivative is written:

            x f(x) - ∑_i (β_i + λ_i) φ_{i+1}(x) √(2i + 2)

        where f(x) is the same GP. This second term is a GP with m+1
        basis functions, and a 0 coefficient in the beginning

        Variable names here follow the notation in Daskalakis, Dellaportas
        and Panos (2020)
        Here, a, b and e correspond as follows:
            a: the precision parameter for the measure
            b: the beta parameter: = (1 + (2 \frac{e}{a})^2)^0.25
            e: the length-scale parameter
        &#34;&#34;&#34;

        # get constant coefficients α, β
        a = self.basis.get_params()[&#34;precision_parameter&#34;]
        e = self.basis.get_params()[&#34;ard_parameter&#34;]
        b = torch.pow((1 + 4 * ((e / a) ** 2)), 0.25)
        first_term_coefficient = (a ** 2 * (1 + b ** 2)).squeeze()
        first_term = (
            first_term_coefficient * x * (self(x) - self.mean_function(x))
        )
        second_term_coefficient = (a * b).squeeze()
        second_term = second_term_coefficient * self.df_second_gp(x)
        third_term = self.mean_function_derivative(x)
        return first_term - second_term + third_term


class HermiteMercerGP(MercerGP):
    &#34;&#34;&#34;
    A Mercer Gaussian process using a truncated smooth exponential kernel
    according to the Mercer kernel formulation.
    &#34;&#34;&#34;

    def __init__(
        self,
        order: int,
        dim: int,
        kernel: MercerKernel,
        mean_function=lambda x: torch.zeros(x.shape),
        mean_function_derivative=lambda x: torch.zeros(x.shape),
    ):
        &#34;&#34;&#34;
        Initialises the Hermite mercer GP by constructing the basis functions
        and the derivative of the mean function.

        :param order: the number of functions to use in the kernel; i.e.,
                      the bandwidth
        :param dim: the dimension of the model. Only really feasible with
                    relatively low numbers due to the exponential behaviour of
                    the tensor product.
        &#34;&#34;&#34;

        se_basis = Basis(
            smooth_exponential_basis, dim, order, kernel.get_params()
        )

        super().__init__(se_basis, order, dim, kernel, mean_function)

        self.mean_function_derivative = mean_function_derivative
        return

    def gen_gp(self):
        &#34;&#34;&#34;
        Returns a HermiteMercerGPSample, which is a function with random
        coefficients on the basis functions.
        &#34;&#34;&#34;
        sample_coefficients = self._get_sample_coefficients()
        # sample_coefficients = torch.zeros(sample_coefficients.shape)
        return HermiteMercerGPSample(
            sample_coefficients + self._get_posterior_coefficients(),
            self.dim,
            self.kernel.get_params(),
            self.mean_function,
            self.mean_function_derivative,
        )


if __name__ == &#34;__main__&#34;:
    &#34;&#34;&#34; &#34;&#34;&#34;
    # parameters for the test
    sample_size = 300

    # build a mercer kernel
    m = 30  # degree of approximation
    dim = 1

    # set up the arguments
    l_se = torch.Tensor([[2]])
    sigma_se = torch.Tensor([3])
    sigma_e = torch.Tensor([1])
    epsilon = torch.Tensor([1])
    mercer_args = {
        &#34;ard_parameter&#34;: l_se,
        &#34;variance_parameter&#34;: sigma_se,
        &#34;noise_parameter&#34;: sigma_e,
        &#34;precision_parameter&#34;: epsilon,
    }

    eigenvalues = smooth_exponential_eigenvalues(m, mercer_args)
    basis = Basis(smooth_exponential_basis, 1, m, mercer_args)
    test_kernel = MercerKernel(m, basis, eigenvalues, mercer_args)

    # build the Mercer kernel examples
    dist = torch.distributions.Normal(loc=0, scale=epsilon)
    inputs = dist.sample([sample_size])
    basis(inputs)
    gram = test_kernel(inputs, inputs) + epsilon * torch.eye(sample_size)

    a = 1
    b = 2
    c = 3

    def data_func(x):
        return a * x ** 2 + b * x + x

    data_points = data_func(inputs) + torch.distributions.Normal(0, 1).sample(
        inputs.shape
    )

    # build a standard kernel for comparison
    # show the two kernels for comparison. They&#39;re close!
    # create pseudodata for training purposes
    mercer_gp = MercerGP(basis, m, dim, test_kernel)
    mercer_gp.add_data(inputs, data_points)

    # test the inverse
    inv_1 = test_kernel.kernel_inverse(inputs)
    inv_3 = torch.inverse(test_kernel(inputs, inputs))
    test_points = torch.linspace(-2, 2, 100)  # .unsqueeze(1)
    test_sample = mercer_gp.gen_gp()  # the problem!
    test_mean = mercer_gp.get_posterior_mean()

    plt.plot(
        test_points.flatten().numpy(),
        test_sample(test_points).flatten().numpy(),
    )
    plt.plot(
        test_points.flatten().numpy(),
        test_mean(test_points).flatten().numpy(),
    )
    plt.plot(
        test_points.flatten().numpy(), data_func(test_points).flatten().numpy()
    )
    plt.scatter(inputs, data_points, marker=&#34;+&#34;)
    plt.show()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="mercergp.MGP.HermiteMercerGP"><code class="flex name class">
<span>class <span class="ident">HermiteMercerGP</span></span>
<span>(</span><span>order: int, dim: int, kernel: <a title="mercergp.kernels.MercerKernel" href="kernels.html#mercergp.kernels.MercerKernel">MercerKernel</a>, mean_function=&lt;function HermiteMercerGP.&lt;lambda&gt;&gt;, mean_function_derivative=&lt;function HermiteMercerGP.&lt;lambda&gt;&gt;)</span>
</code></dt>
<dd>
<div class="desc"><p>A Mercer Gaussian process using a truncated smooth exponential kernel
according to the Mercer kernel formulation.</p>
<p>Initialises the Hermite mercer GP by constructing the basis functions
and the derivative of the mean function.</p>
<p>:param order: the number of functions to use in the kernel; i.e.,
the bandwidth
:param dim: the dimension of the model. Only really feasible with
relatively low numbers due to the exponential behaviour of
the tensor product.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class HermiteMercerGP(MercerGP):
    &#34;&#34;&#34;
    A Mercer Gaussian process using a truncated smooth exponential kernel
    according to the Mercer kernel formulation.
    &#34;&#34;&#34;

    def __init__(
        self,
        order: int,
        dim: int,
        kernel: MercerKernel,
        mean_function=lambda x: torch.zeros(x.shape),
        mean_function_derivative=lambda x: torch.zeros(x.shape),
    ):
        &#34;&#34;&#34;
        Initialises the Hermite mercer GP by constructing the basis functions
        and the derivative of the mean function.

        :param order: the number of functions to use in the kernel; i.e.,
                      the bandwidth
        :param dim: the dimension of the model. Only really feasible with
                    relatively low numbers due to the exponential behaviour of
                    the tensor product.
        &#34;&#34;&#34;

        se_basis = Basis(
            smooth_exponential_basis, dim, order, kernel.get_params()
        )

        super().__init__(se_basis, order, dim, kernel, mean_function)

        self.mean_function_derivative = mean_function_derivative
        return

    def gen_gp(self):
        &#34;&#34;&#34;
        Returns a HermiteMercerGPSample, which is a function with random
        coefficients on the basis functions.
        &#34;&#34;&#34;
        sample_coefficients = self._get_sample_coefficients()
        # sample_coefficients = torch.zeros(sample_coefficients.shape)
        return HermiteMercerGPSample(
            sample_coefficients + self._get_posterior_coefficients(),
            self.dim,
            self.kernel.get_params(),
            self.mean_function,
            self.mean_function_derivative,
        )</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mercergp.MGP.MercerGP" href="#mercergp.MGP.MercerGP">MercerGP</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mercergp.MGP.HermiteMercerGP.gen_gp"><code class="name flex">
<span>def <span class="ident">gen_gp</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a HermiteMercerGPSample, which is a function with random
coefficients on the basis functions.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gen_gp(self):
    &#34;&#34;&#34;
    Returns a HermiteMercerGPSample, which is a function with random
    coefficients on the basis functions.
    &#34;&#34;&#34;
    sample_coefficients = self._get_sample_coefficients()
    # sample_coefficients = torch.zeros(sample_coefficients.shape)
    return HermiteMercerGPSample(
        sample_coefficients + self._get_posterior_coefficients(),
        self.dim,
        self.kernel.get_params(),
        self.mean_function,
        self.mean_function_derivative,
    )</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mercergp.MGP.MercerGP" href="#mercergp.MGP.MercerGP">MercerGP</a></b></code>:
<ul class="hlist">
<li><code><a title="mercergp.MGP.MercerGP.add_data" href="#mercergp.MGP.MercerGP.add_data">add_data</a></code></li>
<li><code><a title="mercergp.MGP.MercerGP.get_inputs" href="#mercergp.MGP.MercerGP.get_inputs">get_inputs</a></code></li>
<li><code><a title="mercergp.MGP.MercerGP.get_outputs" href="#mercergp.MGP.MercerGP.get_outputs">get_outputs</a></code></li>
<li><code><a title="mercergp.MGP.MercerGP.get_posterior_mean" href="#mercergp.MGP.MercerGP.get_posterior_mean">get_posterior_mean</a></code></li>
<li><code><a title="mercergp.MGP.MercerGP.get_targets" href="#mercergp.MGP.MercerGP.get_targets">get_targets</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mercergp.MGP.HermiteMercerGPSample"><code class="flex name class">
<span>class <span class="ident">HermiteMercerGPSample</span></span>
<span>(</span><span>coefficients, dim, params, mean_function, mean_function_derivative)</span>
</code></dt>
<dd>
<div class="desc"><p>Subclassing the MercerGPSample,
this represents specifically a sample from a MercerGP with a truncated
smooth exponential kernel via the use of the Mercer kernel representation.</p>
<p>Modifies the super init to store the mean function callable</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class HermiteMercerGPSample(MercerGPSample):
    &#34;&#34;&#34;
    Subclassing the MercerGPSample,
    this represents specifically a sample from a MercerGP with a truncated
    smooth exponential kernel via the use of the Mercer kernel representation.


    &#34;&#34;&#34;

    def __init__(
        self,
        coefficients,
        dim,
        params,
        mean_function,
        mean_function_derivative,
    ):
        se_basis = Basis(
            smooth_exponential_basis, dim, len(coefficients), params
        )

        derivative_se_basis = Basis(
            smooth_exponential_basis, dim, len(coefficients) + 1, params
        )

        super().__init__(se_basis, coefficients, mean_function)

        # prepare the derivative function for when necessary
        dfc_1 = torch.Tensor(
            [
                torch.sqrt(torch.tensor(2 * (i - 1 + 1)))
                for i in range(self.order + 1)
            ]
        )
        dfc_2 = torch.cat((torch.Tensor([0]), self.coefficients))
        self.df_second_gp = HilbertSpaceElement(
            derivative_se_basis, dfc_1 * dfc_2
        )

        self.mean_function_derivative = mean_function_derivative
        return

    def derivative(self, x):
        &#34;&#34;&#34;
        Returns the derivative of this sample, evaluated at x.

        The MercerGPSample, if using the smooth exponential basis,
        is able to produce its own derivative. This may also be true for
        the Chebyshev ones as well.

        The sample derivative is written:

            x f(x) - ∑_i (β_i + λ_i) φ_{i+1}(x) √(2i + 2)

        where f(x) is the same GP. This second term is a GP with m+1
        basis functions, and a 0 coefficient in the beginning

        Variable names here follow the notation in Daskalakis, Dellaportas
        and Panos (2020)
        Here, a, b and e correspond as follows:
            a: the precision parameter for the measure
            b: the beta parameter: = (1 + (2 \frac{e}{a})^2)^0.25
            e: the length-scale parameter
        &#34;&#34;&#34;

        # get constant coefficients α, β
        a = self.basis.get_params()[&#34;precision_parameter&#34;]
        e = self.basis.get_params()[&#34;ard_parameter&#34;]
        b = torch.pow((1 + 4 * ((e / a) ** 2)), 0.25)
        first_term_coefficient = (a ** 2 * (1 + b ** 2)).squeeze()
        first_term = (
            first_term_coefficient * x * (self(x) - self.mean_function(x))
        )
        second_term_coefficient = (a * b).squeeze()
        second_term = second_term_coefficient * self.df_second_gp(x)
        third_term = self.mean_function_derivative(x)
        return first_term - second_term + third_term</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mercergp.MGP.MercerGPSample" href="#mercergp.MGP.MercerGPSample">MercerGPSample</a></li>
<li><a title="mercergp.MGP.HilbertSpaceElement" href="#mercergp.MGP.HilbertSpaceElement">HilbertSpaceElement</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mercergp.MGP.HermiteMercerGPSample.derivative"><code class="name flex">
<span>def <span class="ident">derivative</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the derivative of this sample, evaluated at x.</p>
<p>The MercerGPSample, if using the smooth exponential basis,
is able to produce its own derivative. This may also be true for
the Chebyshev ones as well.</p>
<p>The sample derivative is written:</p>
<pre><code>x f(x) - ∑_i (β_i + λ_i) φ_{i+1}(x) √(2i + 2)
</code></pre>
<p>where f(x) is the same GP. This second term is a GP with m+1
basis functions, and a 0 coefficient in the beginning</p>
<p>Variable names here follow the notation in Daskalakis, Dellaportas
and Panos (2020)
Here, a, b and e correspond as follows:
a: the precision parameter for the measure
b: the beta parameter: = (1 + (2
rac{e}{a})^2)^0.25
e: the length-scale parameter</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def derivative(self, x):
    &#34;&#34;&#34;
    Returns the derivative of this sample, evaluated at x.

    The MercerGPSample, if using the smooth exponential basis,
    is able to produce its own derivative. This may also be true for
    the Chebyshev ones as well.

    The sample derivative is written:

        x f(x) - ∑_i (β_i + λ_i) φ_{i+1}(x) √(2i + 2)

    where f(x) is the same GP. This second term is a GP with m+1
    basis functions, and a 0 coefficient in the beginning

    Variable names here follow the notation in Daskalakis, Dellaportas
    and Panos (2020)
    Here, a, b and e correspond as follows:
        a: the precision parameter for the measure
        b: the beta parameter: = (1 + (2 \frac{e}{a})^2)^0.25
        e: the length-scale parameter
    &#34;&#34;&#34;

    # get constant coefficients α, β
    a = self.basis.get_params()[&#34;precision_parameter&#34;]
    e = self.basis.get_params()[&#34;ard_parameter&#34;]
    b = torch.pow((1 + 4 * ((e / a) ** 2)), 0.25)
    first_term_coefficient = (a ** 2 * (1 + b ** 2)).squeeze()
    first_term = (
        first_term_coefficient * x * (self(x) - self.mean_function(x))
    )
    second_term_coefficient = (a * b).squeeze()
    second_term = second_term_coefficient * self.df_second_gp(x)
    third_term = self.mean_function_derivative(x)
    return first_term - second_term + third_term</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mercergp.MGP.MercerGPSample" href="#mercergp.MGP.MercerGPSample">MercerGPSample</a></b></code>:
<ul class="hlist">
<li><code><a title="mercergp.MGP.MercerGPSample.get_coefficients" href="#mercergp.MGP.HilbertSpaceElement.get_coefficients">get_coefficients</a></code></li>
<li><code><a title="mercergp.MGP.MercerGPSample.get_order" href="#mercergp.MGP.HilbertSpaceElement.get_order">get_order</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mercergp.MGP.HilbertSpaceElement"><code class="flex name class">
<span>class <span class="ident">HilbertSpaceElement</span></span>
<span>(</span><span>basis, coefficients)</span>
</code></dt>
<dd>
<div class="desc"><p>A class representing an element of
Hilbert space.
That is, for a given basis and set of coefficients, instances of this class
represent functions that belong to the corresponding Hilbert space.</p>
<p>This is useful when producing Mercer Gaussian Processes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class HilbertSpaceElement:
    &#34;&#34;&#34;
    A class representing an element of  Hilbert space.
    That is, for a given basis and set of coefficients, instances of this class
    represent functions that belong to the corresponding Hilbert space.

    This is useful when producing Mercer Gaussian Processes.
    &#34;&#34;&#34;

    def __init__(self, basis, coefficients):
        self.basis = basis
        self.coefficients = coefficients
        self.order = len(coefficients)
        return

    def __call__(self, x):
        &#34;&#34;&#34;
        Evaluates the Hilbert Space element at the given inputs x.
        &#34;&#34;&#34;
        return torch.inner(self.coefficients, self.basis(x)).squeeze()

    def get_order(self):
        &#34;&#34;&#34;
        Getter method for recalling the order of the model; i.e. the bandwidth
        of the kernel whose reproducing space this is an element of.
        &#34;&#34;&#34;
        return self.order

    def get_coefficients(self):
        &#34;&#34;&#34;
        Getter method for recalling the coefficients that this Hilbert Space
        element this is comprised of.
        &#34;&#34;&#34;
        return self.coefficients</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="mercergp.MGP.MercerGPSample" href="#mercergp.MGP.MercerGPSample">MercerGPSample</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mercergp.MGP.HilbertSpaceElement.get_coefficients"><code class="name flex">
<span>def <span class="ident">get_coefficients</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Getter method for recalling the coefficients that this Hilbert Space
element this is comprised of.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_coefficients(self):
    &#34;&#34;&#34;
    Getter method for recalling the coefficients that this Hilbert Space
    element this is comprised of.
    &#34;&#34;&#34;
    return self.coefficients</code></pre>
</details>
</dd>
<dt id="mercergp.MGP.HilbertSpaceElement.get_order"><code class="name flex">
<span>def <span class="ident">get_order</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Getter method for recalling the order of the model; i.e. the bandwidth
of the kernel whose reproducing space this is an element of.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_order(self):
    &#34;&#34;&#34;
    Getter method for recalling the order of the model; i.e. the bandwidth
    of the kernel whose reproducing space this is an element of.
    &#34;&#34;&#34;
    return self.order</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="mercergp.MGP.MercerGP"><code class="flex name class">
<span>class <span class="ident">MercerGP</span></span>
<span>(</span><span>basis: ortho.basis_functions.Basis, order: int, dim: int, kernel: <a title="mercergp.kernels.MercerKernel" href="kernels.html#mercergp.kernels.MercerKernel">MercerKernel</a>, mean_function=&lt;function MercerGP.&lt;lambda&gt;&gt;)</span>
</code></dt>
<dd>
<div class="desc"><dl>
<dt>A class representing a Mercer Gaussian Process.</dt>
<dd>
<p>param basis: a Basis class instance</p>
</dd>
<dd>
<p>param order:
integer describing the maximum order of the kernel
truncation</p>
</dd>
<dt>:param dim: an integer describing the dimension of the model</dt>
<dd>param kernel: a MercerKernel instance</dd>
<dd>param mean_function: a callable representing the
prior mean function for the GP.</dd>
</dl>
<p>Note on the mean_function callable:
Because it is feasible that the mean function might not be expressed
as an element of the Hilbert space, we treat it as a direct callable
function rather than a set of coefficients for the functions in the
same space.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MercerGP:
    &#34;&#34;&#34;
    A class representing a Mercer Gaussian Process.
    &#34;&#34;&#34;

    def __init__(
        self,
        basis: Basis,
        order: int,
        dim: int,
        kernel: MercerKernel,
        mean_function=lambda x: torch.zeros(x.shape),
    ):
        &#34;&#34;&#34;
        : param basis: a Basis class instance
        : param order:  integer describing the maximum order of the kernel
                        truncation
        :param dim: an integer describing the dimension of the model
        : param kernel: a MercerKernel instance
        : param mean_function: a callable representing the
                            prior mean function for the GP.

        Note on the mean_function callable:
        Because it is feasible that the mean function might not be expressed
        as an element of the Hilbert space, we treat it as a direct callable
        function rather than a set of coefficients for the functions in the
        same space.
        &#34;&#34;&#34;
        self.basis = basis
        self.order = order
        self.kernel = kernel
        self.dim = dim

        # data placeholders
        self.x = torch.Tensor([])
        self.y = torch.Tensor([])

        # stored as a closure - see dosctring
        self.mean_function = mean_function
        # self.posterior_coefficients = torch.zeros([self.order])
        return

    def add_data(self, x, y):
        &#34;&#34;&#34;
        Adds observation data for the given MercerGP.

        :param x: the inputs
        :param y: the outputs
        &#34;&#34;&#34;
        # add the inputs and alter the coefficients
        self.x = torch.cat([self.x, x])
        self.y = torch.cat([self.y, y])

        self.posterior_coefficients = self._calculate_posterior_coefficients()
        return

    def get_inputs(self):
        &#34;&#34;&#34;
        Getter method for recalling the inputs that have been passed to the
        MercerGP.
        &#34;&#34;&#34;
        return self.x

    def get_targets(self):
        &#34;&#34;&#34;
        Getter method for recalling the outputs that have been passed to the
        MercerGP.

        Note that this returns the raw targets, rather than processed outputs
        including the mean function m(x).
        For that, MercerGP.get_posterior_mean(x) may be more relevant.
        &#34;&#34;&#34;
        return self.y

    def get_outputs(self):
        &#34;&#34;&#34;
        outputs the data added to the MercerGP minus the mean function
        at the inputs, for correct construction of the coefficients.
        &#34;&#34;&#34;
        return self.y - self.mean_function(self.get_inputs())

    def get_posterior_mean(self):
        &#34;&#34;&#34;
        Returns the posterior mean function.&#34;&#34;&#34;
        return MercerGPSample(
            self.basis, self.posterior_coefficients, self.mean_function
        )

    def gen_gp(self):
        &#34;&#34;&#34;
        Returns a MercerGPSample object representing the sampled Gaussian
        process. It does this by having on it the basis functions and the set
        coefficients.
        &#34;&#34;&#34;
        # return a MercerGPSample
        return MercerGPSample(
            self.basis,
            self._get_sample_coefficients() + self.posterior_coefficients,
            self.mean_function,
        )

    def _calculate_posterior_coefficients(self):
        &#34;&#34;&#34;
        Returns the non-random coefficients for the posterior mean according
        to the kernel as added to the Gaussian process, and under the data
        passed to the Mercer Gaussian process. This will be zeroes for no
        targets

        That is, these are the poeterior mean coefficients related to
        (y-m)&#39;(K(x, x) + σ^2I)^{-1}
        &#34;&#34;&#34;
        interim_matrix = self.kernel.get_interim_matrix_inverse(self.x)
        ksi = self.kernel.get_ksi(self.x)

        posterior_coefficients = torch.einsum(
            &#34;jm, mn -&gt; jn&#34;, interim_matrix, ksi.t()
        )
        these_outputs = self.get_outputs()
        result = torch.einsum(
            &#34;i..., ji -&gt; j&#34;, these_outputs, posterior_coefficients
        )
        return result

    def _get_sample_coefficients(self):
        &#34;&#34;&#34;
        Returns random coefficients for a sample according to the kernel.

        Combined with posterior coefficients, these are used to produce a GP
        sample.
        &#34;&#34;&#34;
        mean = torch.zeros([self.order])
        variance = self.kernel.get_interim_matrix_inverse(self.x)
        # variance *= 100
        if (variance != torch.abs(variance)).all():
            breakpoint()
        # variance += 0.001 * torch.eye(variance.shape[0])
        normal_rv = (
            torch.distributions.MultivariateNormal(
                loc=mean, covariance_matrix=variance
            )
            .sample([1])
            .squeeze()
        )
        return normal_rv

    def set_posterior_coefficients(self, coefficients):
        self.posterior_coefficients = coefficients</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="mercergp.MGP.HermiteMercerGP" href="#mercergp.MGP.HermiteMercerGP">HermiteMercerGP</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mercergp.MGP.MercerGP.add_data"><code class="name flex">
<span>def <span class="ident">add_data</span></span>(<span>self, x, y)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds observation data for the given MercerGP.</p>
<p>:param x: the inputs
:param y: the outputs</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_data(self, x, y):
    &#34;&#34;&#34;
    Adds observation data for the given MercerGP.

    :param x: the inputs
    :param y: the outputs
    &#34;&#34;&#34;
    # add the inputs and alter the coefficients
    self.x = torch.cat([self.x, x])
    self.y = torch.cat([self.y, y])

    self.posterior_coefficients = self._calculate_posterior_coefficients()
    return</code></pre>
</details>
</dd>
<dt id="mercergp.MGP.MercerGP.gen_gp"><code class="name flex">
<span>def <span class="ident">gen_gp</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a MercerGPSample object representing the sampled Gaussian
process. It does this by having on it the basis functions and the set
coefficients.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gen_gp(self):
    &#34;&#34;&#34;
    Returns a MercerGPSample object representing the sampled Gaussian
    process. It does this by having on it the basis functions and the set
    coefficients.
    &#34;&#34;&#34;
    # return a MercerGPSample
    return MercerGPSample(
        self.basis,
        self._get_sample_coefficients() + self.posterior_coefficients,
        self.mean_function,
    )</code></pre>
</details>
</dd>
<dt id="mercergp.MGP.MercerGP.get_inputs"><code class="name flex">
<span>def <span class="ident">get_inputs</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Getter method for recalling the inputs that have been passed to the
MercerGP.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_inputs(self):
    &#34;&#34;&#34;
    Getter method for recalling the inputs that have been passed to the
    MercerGP.
    &#34;&#34;&#34;
    return self.x</code></pre>
</details>
</dd>
<dt id="mercergp.MGP.MercerGP.get_outputs"><code class="name flex">
<span>def <span class="ident">get_outputs</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>outputs the data added to the MercerGP minus the mean function
at the inputs, for correct construction of the coefficients.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_outputs(self):
    &#34;&#34;&#34;
    outputs the data added to the MercerGP minus the mean function
    at the inputs, for correct construction of the coefficients.
    &#34;&#34;&#34;
    return self.y - self.mean_function(self.get_inputs())</code></pre>
</details>
</dd>
<dt id="mercergp.MGP.MercerGP.get_posterior_mean"><code class="name flex">
<span>def <span class="ident">get_posterior_mean</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the posterior mean function.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_posterior_mean(self):
    &#34;&#34;&#34;
    Returns the posterior mean function.&#34;&#34;&#34;
    return MercerGPSample(
        self.basis, self.posterior_coefficients, self.mean_function
    )</code></pre>
</details>
</dd>
<dt id="mercergp.MGP.MercerGP.get_targets"><code class="name flex">
<span>def <span class="ident">get_targets</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Getter method for recalling the outputs that have been passed to the
MercerGP.</p>
<p>Note that this returns the raw targets, rather than processed outputs
including the mean function m(x).
For that, MercerGP.get_posterior_mean(x) may be more relevant.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_targets(self):
    &#34;&#34;&#34;
    Getter method for recalling the outputs that have been passed to the
    MercerGP.

    Note that this returns the raw targets, rather than processed outputs
    including the mean function m(x).
    For that, MercerGP.get_posterior_mean(x) may be more relevant.
    &#34;&#34;&#34;
    return self.y</code></pre>
</details>
</dd>
<dt id="mercergp.MGP.MercerGP.set_posterior_coefficients"><code class="name flex">
<span>def <span class="ident">set_posterior_coefficients</span></span>(<span>self, coefficients)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_posterior_coefficients(self, coefficients):
    self.posterior_coefficients = coefficients</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="mercergp.MGP.MercerGPSample"><code class="flex name class">
<span>class <span class="ident">MercerGPSample</span></span>
<span>(</span><span>basis, coefficients, mean_function)</span>
</code></dt>
<dd>
<div class="desc"><p>Subclassing the HilbertSpaceElement,
this adds a passed mean function so as to represent a GP sample function.</p>
<p>Modifies the super init to store the mean function callable</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MercerGPSample(HilbertSpaceElement):
    &#34;&#34;&#34;
    Subclassing the HilbertSpaceElement,
    this adds a passed mean function so as to represent a GP sample function.
    &#34;&#34;&#34;

    def __init__(self, basis, coefficients, mean_function):
        &#34;&#34;&#34;
        Modifies the super init to store the mean function callable
        &#34;&#34;&#34;
        super().__init__(basis, coefficients)
        self.mean_function = mean_function
        return

    def __call__(self, x):
        &#34;&#34;&#34;
        Adds the mean function evaluation to the MercerGPSample
        &#34;&#34;&#34;
        return super().__call__(x) + self.mean_function(x)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mercergp.MGP.HilbertSpaceElement" href="#mercergp.MGP.HilbertSpaceElement">HilbertSpaceElement</a></li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="mercergp.MGP.HermiteMercerGPSample" href="#mercergp.MGP.HermiteMercerGPSample">HermiteMercerGPSample</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mercergp.MGP.HilbertSpaceElement" href="#mercergp.MGP.HilbertSpaceElement">HilbertSpaceElement</a></b></code>:
<ul class="hlist">
<li><code><a title="mercergp.MGP.HilbertSpaceElement.get_coefficients" href="#mercergp.MGP.HilbertSpaceElement.get_coefficients">get_coefficients</a></code></li>
<li><code><a title="mercergp.MGP.HilbertSpaceElement.get_order" href="#mercergp.MGP.HilbertSpaceElement.get_order">get_order</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="mercergp" href="index.html">mercergp</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="mercergp.MGP.HermiteMercerGP" href="#mercergp.MGP.HermiteMercerGP">HermiteMercerGP</a></code></h4>
<ul class="">
<li><code><a title="mercergp.MGP.HermiteMercerGP.gen_gp" href="#mercergp.MGP.HermiteMercerGP.gen_gp">gen_gp</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mercergp.MGP.HermiteMercerGPSample" href="#mercergp.MGP.HermiteMercerGPSample">HermiteMercerGPSample</a></code></h4>
<ul class="">
<li><code><a title="mercergp.MGP.HermiteMercerGPSample.derivative" href="#mercergp.MGP.HermiteMercerGPSample.derivative">derivative</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mercergp.MGP.HilbertSpaceElement" href="#mercergp.MGP.HilbertSpaceElement">HilbertSpaceElement</a></code></h4>
<ul class="">
<li><code><a title="mercergp.MGP.HilbertSpaceElement.get_coefficients" href="#mercergp.MGP.HilbertSpaceElement.get_coefficients">get_coefficients</a></code></li>
<li><code><a title="mercergp.MGP.HilbertSpaceElement.get_order" href="#mercergp.MGP.HilbertSpaceElement.get_order">get_order</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mercergp.MGP.MercerGP" href="#mercergp.MGP.MercerGP">MercerGP</a></code></h4>
<ul class="">
<li><code><a title="mercergp.MGP.MercerGP.add_data" href="#mercergp.MGP.MercerGP.add_data">add_data</a></code></li>
<li><code><a title="mercergp.MGP.MercerGP.gen_gp" href="#mercergp.MGP.MercerGP.gen_gp">gen_gp</a></code></li>
<li><code><a title="mercergp.MGP.MercerGP.get_inputs" href="#mercergp.MGP.MercerGP.get_inputs">get_inputs</a></code></li>
<li><code><a title="mercergp.MGP.MercerGP.get_outputs" href="#mercergp.MGP.MercerGP.get_outputs">get_outputs</a></code></li>
<li><code><a title="mercergp.MGP.MercerGP.get_posterior_mean" href="#mercergp.MGP.MercerGP.get_posterior_mean">get_posterior_mean</a></code></li>
<li><code><a title="mercergp.MGP.MercerGP.get_targets" href="#mercergp.MGP.MercerGP.get_targets">get_targets</a></code></li>
<li><code><a title="mercergp.MGP.MercerGP.set_posterior_coefficients" href="#mercergp.MGP.MercerGP.set_posterior_coefficients">set_posterior_coefficients</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mercergp.MGP.MercerGPSample" href="#mercergp.MGP.MercerGPSample">MercerGPSample</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>